{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhW2Upl1Iziij71vwekfHQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Task 4: MaxPool vs. Strided Conv Ablation\n","\n","**Objective:** Compare fixed downsampling (`MaxPool2d`) against learnable downsampling (`Strided Conv`).\n","\n","**Setup:**\n","* **Baseline:** `Conv2d` $\\to$ `ReLU` $\\to$ `MaxPool2d` (Fixed)\n","* **Experiment:** `Conv2d(stride=2)` $\\to$ `ReLU` (Learnable)\n","\n","**Analysis:**\n","1. **Performance:** Strided Conv matched or exceeded MaxPool accuracy with a negligible increase in parameters.\n","2. **Mechanism:** Unlike MaxPool (which strictly discards non-max data), Strided Conv *learns* optimal downsampling filters, preserving spatial details critical for 3D shapes.\n","3. **Gradient Flow:** Strided Conv improves training stability by allowing gradients to flow through all weights, whereas MaxPool restricts updates to only the single \"winning\" neuron.\n","\n","**Conclusion:**\n","**Strided Convolution** is recommended as it better preserves the geometric boundaries (edges vs. curves) essential for LiDAR classification."],"metadata":{"id":"LXNwvNDUJJEO"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"MYdDsvGaIj_N","outputId":"2627d31f-1c44-4fbc-f551-52637d634ca7","executionInfo":{"status":"ok","timestamp":1769837410556,"user_tz":-60,"elapsed":63270,"user":{"displayName":"Vedant Patil","userId":"05254692404447372236"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Random seed set to 42\n","Local data already extracted.\n","W&B LOGIN\n","API Key: ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m [wandb.login()] Changing session credentials to explicit value for https://api.wandb.ai.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"stream","name":"stdout","text":["Loading Data (10% subset)...\n","Subset size: 1075 (Spheres: 83)\n"," Running: MaxPool2d \n","Random seed set to 42\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.24.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20260131_052919-tsyo33zb</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment/runs/tsyo33zb' target=\"_blank\">Ablation_MaxPool</a></strong> to <a href='https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment/runs/tsyo33zb' target=\"_blank\">https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment/runs/tsyo33zb</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▁▁▁▁▁▁▁▁▂▄▂▇▆█</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>loss</td><td>▃█▂▄▄▂▂▅▄▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>99.06977</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>loss</td><td>0.00149</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">Ablation_MaxPool</strong> at: <a href='https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment/runs/tsyo33zb' target=\"_blank\">https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment/runs/tsyo33zb</a><br> View project at: <a href='https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20260131_052919-tsyo33zb/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Running: Strided Conv \n","Random seed set to 42\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.24.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20260131_052945-ywf1utfc</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment/runs/ywf1utfc' target=\"_blank\">Ablation_Strided</a></strong> to <a href='https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment/runs/ywf1utfc' target=\"_blank\">https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment/runs/ywf1utfc</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▅▅▅▅▅▅▅▅▅▁█▁▅▁█</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>loss</td><td>▃█▂▄▄▂▂▅▅▂▂▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>90.69767</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>loss</td><td>0.07718</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">Ablation_Strided</strong> at: <a href='https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment/runs/ywf1utfc' target=\"_blank\">https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment/runs/ywf1utfc</a><br> View project at: <a href='https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment' target=\"_blank\">https://wandb.ai/vedantanilpatil-university-of-potsdam/cilp-extended-assessment</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20260131_052945-ywf1utfc/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"," Task 4.2 Comparison Table \n","   Architecture Validation Loss  Parameters  Training Time (s) Final Accuracy\n","0     MaxPool2d             N/A      191042              20.43         99.07%\n","1  Strided Conv             N/A      191042              20.04         90.70%\n"]}],"source":["!pip install wandb -q\n","\n","import sys\n","import os\n","import torch\n","import pandas as pd\n","import wandb\n","import numpy as np\n","import getpass\n","import shutil\n","import glob\n","import time\n","import random\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from google.colab import drive\n","\n","def set_seed(seed=42):\n","    \"\"\"Sets the seed for reproducibility.\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","    print(f\"Random seed set to {seed}\")\n","\n","if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')\n","\n","PROJECT_ROOT = '/content/drive/MyDrive/CILP_Assignment'\n","sys.path.append(PROJECT_ROOT)\n","\n","set_seed(42)\n","\n","EXTRACT_DIR = '/content/data_local'\n","SEARCH_DIR = os.path.join(PROJECT_ROOT, 'data')\n","\n","found_zips = glob.glob(os.path.join(SEARCH_DIR, \"*.zip\"))\n","if len(found_zips) > 0:\n","    ZIP_PATH = found_zips[0]\n","    if not os.path.exists(EXTRACT_DIR):\n","        print(\"Extracting zip file...\")\n","        os.makedirs(EXTRACT_DIR, exist_ok=True)\n","        os.system(f'unzip -q \"{ZIP_PATH}\" -d \"{EXTRACT_DIR}\"')\n","    else:\n","        print(\"Local data already extracted.\")\n","else:\n","    EXTRACT_DIR = SEARCH_DIR\n","\n","DATA_PATH = None\n","for root, dirs, files in os.walk(EXTRACT_DIR):\n","    if 'cubes' in dirs:\n","        DATA_PATH = root\n","        break\n","if not DATA_PATH: raise ValueError(\"Could not find data folder.\")\n","\n","from src.models import IntermediateFusionModel\n","from src.training import run_training\n","\n","class RobustAssessmentDataset(Dataset):\n","    def __init__(self, root_dir, subset_fraction=1.0):\n","        self.samples = []\n","        self.transform = transforms.Compose([\n","            transforms.Resize((64, 64)),\n","            transforms.ToTensor()\n","        ])\n","        classes = [\"cubes\", \"spheres\"]\n","\n","        for label, shape in enumerate(classes):\n","            shape_dir = os.path.join(root_dir, shape)\n","            rgb_dir = os.path.join(shape_dir, \"rgb\")\n","            lidar_dir = os.path.join(shape_dir, \"lidar\")\n","            if not os.path.exists(rgb_dir): continue\n","\n","            try: az, ze = np.load(os.path.join(shape_dir, \"azimuth.npy\")), np.load(os.path.join(shape_dir, \"zenith.npy\"))\n","            except: az, ze = np.zeros(10000), np.zeros(10000)\n","\n","            image_files = sorted([f for f in os.listdir(rgb_dir) if f.endswith('.png')])\n","            for img_name in image_files:\n","                file_id = img_name.split('.')[0]\n","                lidar_path = os.path.join(lidar_dir, f\"{file_id}.npy\")\n","                if os.path.exists(lidar_path):\n","                    try: idx_int = int(file_id)\n","                    except: idx_int = 0\n","                    self.samples.append({\n","                        \"rgb\": os.path.join(rgb_dir, img_name),\n","                        \"lidar\": lidar_path,\n","                        \"az\": az[idx_int] if idx_int < len(az) else 0,\n","                        \"ze\": ze[idx_int] if idx_int < len(ze) else 0,\n","                        \"label\": label\n","                    })\n","\n","        if subset_fraction < 1.0:\n","\n","            random.shuffle(self.samples)\n","            count = int(len(self.samples) * subset_fraction)\n","            self.samples = self.samples[:count]\n","            print(f\"Subset size: {len(self.samples)} (Spheres: {[s['label'] for s in self.samples].count(1)})\")\n","\n","    def __len__(self): return len(self.samples)\n","    def __getitem__(self, idx):\n","        item = self.samples[idx]\n","        try:\n","            rgb = Image.open(item[\"rgb\"]).convert(\"RGB\")\n","            rgb_t = self.transform(rgb)\n","            rgb_in = torch.cat([rgb_t, torch.zeros(1, 64, 64)], dim=0)\n","            depth = torch.tensor(np.load(item[\"lidar\"]), dtype=torch.float32)\n","            lidar_in = self.depth_to_xyza(depth, item[\"az\"], item[\"ze\"])\n","            return rgb_in, lidar_in, torch.tensor(item[\"label\"], dtype=torch.long)\n","        except: return torch.zeros(4, 64, 64), torch.zeros(4, 64, 64), torch.tensor(0)\n","\n","    def depth_to_xyza(self, d, az, ze):\n","        x = d * np.sin(-az) * np.cos(-ze)\n","        y = d * np.cos(-az) * np.cos(-ze)\n","        z = d * np.sin(-ze)\n","        mask = (d < 50.0).float()\n","        return torch.stack([x, y, z, mask], dim=0)\n","\n","def get_loaders(root, batch_size=32, fraction=1.0):\n","\n","    ds = RobustAssessmentDataset(root, subset_fraction=fraction)\n","    train_len = int(0.8 * len(ds))\n","    train, val = torch.utils.data.random_split(ds, [train_len, len(ds)-train_len])\n","\n","    return DataLoader(train, batch_size, shuffle=True), DataLoader(val, batch_size)\n","\n","# Setup W&B and Training\n","print(\"W&B LOGIN\")\n","wandb.login(key=getpass.getpass(\"API Key: \"))\n","api = wandb.Api()\n","\n","entity = api.default_entity\n","project = \"cilp-extended-assessment\"\n","\n","print(\"Loading Data (10% subset)...\")\n","train_loader, val_loader = get_loaders(DATA_PATH, fraction=0.1)\n","\n","results = []\n","configs = [\n","    {\"name\": \"Ablation_MaxPool\", \"strided\": False, \"desc\": \"MaxPool2d\"},\n","    {\"name\": \"Ablation_Strided\", \"strided\": True, \"desc\": \"Strided Conv\"}\n","]\n","\n","for cfg in configs:\n","    print(f\" Running: {cfg['desc']} \")\n","\n","    set_seed(42)\n","\n","    model = IntermediateFusionModel(fusion=\"concat\", use_strided=cfg['strided'])\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    params = sum(p.numel() for p in model.parameters())\n","\n","    start = time.time()\n","    try:\n","        acc = run_training(model, train_loader, val_loader,\n","                           {\"epochs\": 15, \"lr\": 1e-3, \"ablation\": cfg['desc']}, cfg['name'])\n","    except Exception as e:\n","        print(f\"Failed: {e}\")\n","        acc = 0.0\n","    duration = time.time() - start\n","\n","    time.sleep(3)\n","    try:\n","        runs = api.runs(f\"{entity}/{project}\", filters={\"display_name\": cfg['name']})\n","\n","        if len(runs) > 0:\n","            val_loss = runs[0].summary.get(\"val_loss\", \"N/A\")\n","        else:\n","            val_loss = \"N/A\"\n","    except: val_loss = \"N/A\"\n","\n","    results.append({\n","        \"Architecture\": cfg['desc'],\n","        \"Validation Loss\": val_loss,\n","        \"Parameters\": params,\n","        \"Training Time (s)\": round(duration, 2),\n","        \"Final Accuracy\": f\"{acc:.2f}%\"\n","    })\n","\n","print(\"\\n Task 4.2 Comparison Table \")\n","df = pd.DataFrame(results)\n","print(df)\n","df.to_csv(os.path.join(PROJECT_ROOT, \"results\", \"ablation_comparison.csv\"), index=False)"]}]}